{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "This dataset was sourced from Kaggle 'Retail Credit Bank Data'. \n",
    "\n",
    "A retail credit bank would like us to build a credit default model for their credit card portfolio. Datset consists of 13,444 observations and 14 variables. The description for the variables are listed below:\n",
    "\n",
    "1. *CARDHLDR* Dummy variable, 1 if application for credit card accepted, 0 if not\n",
    "2. *DEFAULT* 1 if defaulted 0 if not (observed when CARDHLDR=1, 10,499 observations)\n",
    "3. *AGE* Age in years plus twelfths of a year\n",
    "4. *ACADMOS* months living at current address\n",
    "5. ADEPCNT 1 + number of dependents\n",
    "6. MAJORDRG Number of major derogatory reports\n",
    "7. MINORDRG Number of minor derogatory reports\n",
    "8. OWNRENT 1 if owns their home, 0 if rent\n",
    "9. *INCOME* Monthly income (divided by 10,000)\n",
    "10. SELFEMPL 1 if self employed, 0 if not\n",
    "11. *INCPER* Income divided by number of dependents\n",
    "12. EXP_INC Ratio of monthly credit card expenditure to yearly income\n",
    "13. SPENDING Average monthly credit card expenditure (for CARDHOLDER = 1)\n",
    "14. LOGSPEND Log of spending\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "1. Identify the accuracy of model at predicting a default\n",
    "\n",
    "2. identify which factors most significantly increase or decrease likelihood of credit default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "1. Exploratory Data Analysis\n",
    "2. Data Transformation\n",
    "3. Data Aggregation\n",
    "4. Analysis\n",
    "5. Insight Summary\n",
    "6. Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Exploratory Data Analysis\n",
    "\n",
    "First and foremost, let's familiarize ourselves with the data. There are always questions you need to ask your data\n",
    "+ Is the data set clean?\n",
    "+ What are the data types?\n",
    "+ What the actual data looks like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   CARDHLDR  DEFAULT        AGE  ACADMOS  ADEPCNT  MAJORDRG  MINORDRG  \\\n",
      "0         0        0  27.250000        4        0         0         0   \n",
      "1         0        0  40.833332      111        3         0         0   \n",
      "2         1        0  37.666668       54        3         0         0   \n",
      "3         1        0  42.500000       60        3         0         0   \n",
      "4         1        0  21.333334        8        0         0         0   \n",
      "\n",
      "   OWNRENT       INCOME  SELFEMPL   INCPER   EXP_INC     SPENDING   LOGSPEND   \n",
      "0        0  1200.000000         0  18000.0  0.000667                           \n",
      "1        1  4000.000000         0  13500.0  0.000222                           \n",
      "2        1  3666.666667         0  11300.0  0.033270  121.9896773  4.8039364   \n",
      "3        1  2000.000000         0  17250.0  0.048427   96.8536213  4.5732008   \n",
      "4        0  2916.666667         0  35000.0  0.016523   48.1916700  3.8751862   \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13444 entries, 0 to 13443\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   CARDHLDR   13444 non-null  int64  \n",
      " 1   DEFAULT    13444 non-null  int64  \n",
      " 2   AGE        13444 non-null  float64\n",
      " 3   ACADMOS    13444 non-null  int64  \n",
      " 4   ADEPCNT    13444 non-null  int64  \n",
      " 5   MAJORDRG   13444 non-null  int64  \n",
      " 6   MINORDRG   13444 non-null  int64  \n",
      " 7   OWNRENT    13444 non-null  int64  \n",
      " 8   INCOME     13444 non-null  float64\n",
      " 9   SELFEMPL   13444 non-null  int64  \n",
      " 10  INCPER     13444 non-null  float64\n",
      " 11  EXP_INC    13444 non-null  float64\n",
      " 12  SPENDING   13444 non-null  object \n",
      " 13  LOGSPEND   13444 non-null  object \n",
      "dtypes: float64(4), int64(8), object(2)\n",
      "memory usage: 1.4+ MB\n",
      "None\n",
      "           CARDHLDR       DEFAULT           AGE       ACADMOS       ADEPCNT  \\\n",
      "count  13444.000000  13444.000000  13444.000000  13444.000000  13444.000000   \n",
      "mean       0.780943      0.074085     33.471828     55.318878      1.017257   \n",
      "std        0.413623      0.261919     10.226484     63.089729      1.279098   \n",
      "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
      "25%        1.000000      0.000000     25.666666     12.000000      0.000000   \n",
      "50%        1.000000      0.000000     31.500000     30.000000      1.000000   \n",
      "75%        1.000000      0.000000     39.333332     72.000000      2.000000   \n",
      "max        1.000000      1.000000     88.666664    576.000000      9.000000   \n",
      "\n",
      "           MAJORDRG      MINORDRG       OWNRENT        INCOME      SELFEMPL  \\\n",
      "count  13444.000000  13444.000000  13444.000000  13444.000000  13444.000000   \n",
      "mean       0.462809      0.290539      0.455965   2509.527819      0.057944   \n",
      "std        1.432724      0.767620      0.498076   1252.946716      0.233646   \n",
      "min        0.000000      0.000000      0.000000     50.000000      0.000000   \n",
      "25%        0.000000      0.000000      0.000000   1666.666667      0.000000   \n",
      "50%        0.000000      0.000000      0.000000   2166.666667      0.000000   \n",
      "75%        0.000000      0.000000      1.000000   2916.666667      0.000000   \n",
      "max       22.000000     11.000000      1.000000   8333.250000      1.000000   \n",
      "\n",
      "              INCPER       EXP_INC  \n",
      "count   13444.000000  13444.000000  \n",
      "mean    21719.680793      0.070974  \n",
      "std     13591.209469      0.103922  \n",
      "min       362.500000      0.000088  \n",
      "25%     12000.000000      0.002706  \n",
      "50%     19000.000000      0.039286  \n",
      "75%     27658.666504      0.095655  \n",
      "max    150000.000000      2.037728  \n"
     ]
    }
   ],
   "source": [
    "#import necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "DATA_FILE = 'credit_data.csv'\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "print(df.head())\n",
    "print(df.info())\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know some information about the dataset's attributes, we can select our target variable and features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable: Predicting whether an accepted cardholder defaults.\n",
    "TARGET_COLUMN_NAME = 'DEFAULT'\n",
    "\n",
    "# Features relevant to the default decision. (Using bolded columns from your list,\n",
    "# plus some other strong indicators like ACADMOS and MAJORDRG).\n",
    "# NOTE: SPENDING and LOGSPEND are only observed when CARDHLDR=1, so they are ideal features here.\n",
    "FEATURES_TO_USE = [\n",
    "    'AGE', 'ACADMOS', 'ADEPCNT', 'MAJORDRG', 'MINORDRG',\n",
    "    'OWNRENT', 'INCOME', 'SELFEMPL', 'INCPER', 'EXP_INC',\n",
    "    'SPENDING', 'LOGSPEND '\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Transformation\n",
    "Here we will\n",
    "+ Filter the data based on the required Features and the Target column\n",
    "+ Clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Original samples: 13444\n",
      "   Filtered samples (CARDHLDR=1): 10499\n",
      "\n",
      "   Final samples after dropping NaNs: 10499\n"
     ]
    }
   ],
   "source": [
    "# Crucial Step: Filter the data set to only include observations\n",
    "# where the DEFAULT status is known (i.e., card application was accepted).\n",
    "df_filtered = df[df['CARDHLDR'] == 1].copy()\n",
    "print(f\"   Original samples: {len(df)}\")\n",
    "print(f\"   Filtered samples (CARDHLDR=1): {len(df_filtered)}\\n\")\n",
    "# a) Select the required Features and Target\n",
    "X_raw = df_filtered[FEATURES_TO_USE]\n",
    "y = df_filtered[TARGET_COLUMN_NAME]\n",
    "\n",
    "# b) Handle Missing Values (NaNs)\n",
    "# Simple approach: Drop rows with ANY missing data in the selected features or target.\n",
    "data_combined = pd.concat([X_raw, y], axis=1).dropna()\n",
    "X = data_combined[FEATURES_TO_USE]\n",
    "y = data_combined[TARGET_COLUMN_NAME]\n",
    "print(f\"   Final samples after dropping NaNs: {len(X)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Training and Testing\n",
    "\n",
    "Split Data into Training and Testing Sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features (X) shape: (10499, 12), Target (y) shape: (10499,)\n",
      "\n",
      "Step 3: Splitting Data...\n",
      "   Training samples: 7349\n",
      "   Testing samples: 3150\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"   Features (X) shape: {X.shape}, Target (y) shape: {y.shape}\\n\")\n",
    "\n",
    "\n",
    "# Step 3: Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "print(\"Step 3: Splitting Data...\")\n",
    "print(f\"   Training samples: {len(X_train)}\")\n",
    "print(f\"   Testing samples: {len(X_test)}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train Logistic Regression Model\n",
    "\n",
    "Were going to initialize and train the Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Features (X) shape: (10499, 12), Target (y) shape: (10499,)\n",
      "\n",
      "Splitting Data...\n",
      "   Training samples: 7349\n",
      "   Testing samples: 3150\n",
      "\n",
      "Step 4: Training Logistic Regression Model...\n",
      "   Model training complete.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"   Features (X) shape: {X.shape}, Target (y) shape: {y.shape}\\n\")\n",
    "\n",
    "\n",
    "# Step 3: Split Data into Training and Testing Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "print(\"Splitting Data...\")\n",
    "print(f\"   Training samples: {len(X_train)}\")\n",
    "print(f\"   Testing samples: {len(X_test)}\\n\")\n",
    "\n",
    "#4.A Initialize and Train the Logistic Regression Model\n",
    "model = LogisticRegression(random_state=42, solver='liblinear')\n",
    "print(\"Step 4: Training Logistic Regression Model...\")\n",
    "model.fit(X_train, y_train)\n",
    "print(\"   Model training complete.\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking for Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Model Performance...\n",
      "   Model Accuracy on Test Set: 90.73%\n",
      "\n",
      "--- Confusion Matrix ---\n",
      "   [[True Negatives (Correctly predicted NOT to default), False Positives (Incorrectly predicted to default)]\n",
      "    [False Negatives (Incorrectly predicted NOT to default), True Positives (Correctly predicted to default)]]\n",
      "[[2858    0]\n",
      " [ 292    0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(\"Evaluating Model Performance...\")\n",
    "print(f\"   Model Accuracy on Test Set: {accuracy * 100:.2f}%\")\n",
    "print(\"\\n--- Confusion Matrix ---\")\n",
    "print(\"   [[True Negatives (Correctly predicted NOT to default), False Positives (Incorrectly predicted to default)]\")\n",
    "print(\"    [False Negatives (Incorrectly predicted NOT to default), True Positives (Correctly predicted to default)]]\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Insight Summary\n",
    "The model's accuracy at predicting is at 90.73%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Identify which attribute are the most important predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. changing from y_pred to predict_proba, to get the probability score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilities = model.predict_proba(X_test)[:, 1] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Set threshould at 20%, meaning predict default if probability is greater than 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pred = (probabilities > 0.2).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix using 20% Probability Threshold:\n",
      "[[2800   58]\n",
      " [ 270   22]]\n"
     ]
    }
   ],
   "source": [
    "custom_conf_matrix = confusion_matrix(y_test, custom_pred)\n",
    "print(\"\\nConfusion Matrix using 20% Probability Threshold:\")\n",
    "print(custom_conf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. After model is trained, features with largest absolute coefficient values (positive or negative) are the most important predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Model Coefficients (Feature Importance) ---\n",
      "MINORDRG     0.012643\n",
      "MAJORDRG     0.007143\n",
      "ADEPCNT      0.001732\n",
      "SELFEMPL     0.000788\n",
      "ACADMOS      0.000780\n",
      "INCPER      -0.000018\n",
      "EXP_INC     -0.000114\n",
      "SPENDING    -0.000123\n",
      "INCOME      -0.000422\n",
      "OWNRENT     -0.003291\n",
      "AGE         -0.020991\n",
      "LOGSPEND    -0.040245\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Model Coefficients (Feature Importance) ---\")\n",
    "coefficients = pd.Series(model.coef_[0], index=X.columns)\n",
    "print(coefficients.sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "A large positive coefficient for MINORDRG means that feature strongly increases the likelihood of default. A large negative coefficient LOGSPEND means that feature strongly decreases the likelihood of default."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
